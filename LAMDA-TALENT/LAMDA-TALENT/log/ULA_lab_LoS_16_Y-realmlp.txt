using gpu: 0
{'batch_size': 1024,
 'cat_min_frequency': 0.0,
 'cat_nan_policy': 'new',
 'cat_policy': 'indices',
 'config': {'general': {},
            'model': {'act': 'selu',
                      'add_front_scale': True,
                      'hidden_sizes': [256, 256, 256],
                      'lr': 0.04,
                      'ls_eps': 0.1,
                      'num_emb_type': 'pbld',
                      'p_drop': 0.15,
                      'plr_sigma': 0.1,
                      'wd': 0.02},
            'training': {}},
 'dataset': 'ULA_lab_LoS_16_Y',
 'dataset_path': 'data',
 'evaluate_option': 'best-val',
 'gpu': '0',
 'max_epoch': 200,
 'model_path': 'results_model',
 'model_type': 'realmlp',
 'n_bins': 2,
 'n_trials': 20,
 'normalization': 'standard',
 'num_nan_policy': 'mean',
 'num_policy': 'none',
 'retune': False,
 'save_path': 'results_model/ULA_lab_LoS_16_Y-realmlp/Epoch200BZ1024-Norm-standard-Nan-mean-new-Cat-indices',
 'seed': 0,
 'seed_num': 1,
 'tune': False,
 'workers': 0}
{'model': {'num_emb_type': 'pbld', 'add_front_scale': True, 'lr': 0.04, 'p_drop': 0.15, 'act': 'selu', 'hidden_sizes': [256, 256, 256], 'wd': 0.02, 'plr_sigma': 0.1, 'ls_eps': 0.1}, 'training': {'n_bins': 2}, 'general': {}}
